{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice."
      ],
      "metadata": {
        "id": "LJ7uRivve4Zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both multithreading and multiprocessing are used to achieve parallelism and improve performance, but they differ in how they handle tasks, system resources, and the type of problems they are suited for. Below is a breakdown of scenarios where each approach is preferable:\n",
        "\n",
        "***When Multithreading is Preferable:***\n",
        "\n",
        "Multithreading is generally better when your tasks are I/O-bound, and the bottleneck is not CPU performance but waiting for external resources like disk, network, or database access.\n",
        "\n",
        "1. I/O-bound tasks:\n",
        "\n",
        "Network communication: When tasks are waiting on network I/O (e.g., downloading data from a server or interacting with an API), multithreading allows other threads to perform tasks while waiting.\n",
        "\n",
        "File operations: Reading/writing to disk or accessing remote databases/filesystems can benefit from multithreading since I/O operations tend to be slow, and multiple threads can work in parallel.\n",
        "\n",
        "Web scraping: When scraping data from multiple websites, threads can be used to handle multiple HTTP requests concurrently, improving the speed of gathering data.\n",
        "\n",
        "2. Tasks with low CPU usage:\n",
        "\n",
        "GUI applications: In GUI-based programs, a separate thread can be used to run background tasks (like updating UI elements, fetching data) without freezing the interface.\n",
        "\n",
        "User input handling: Programs that wait for user input (like command-line tools or games) often use threads to manage different input/output events concurrently.\n",
        "\n",
        "3. Lightweight concurrency:\n",
        "\n",
        "Small memory footprint: Threads share the same memory space, making them more lightweight in terms of memory usage compared to processes, which require separate memory spaces.\n",
        "\n",
        "Concurrency on shared data: When tasks involve frequently sharing or updating data, such as using shared memory, multithreading is easier to manage since all threads share the same memory. Proper use of synchronization primitives (locks, semaphores, etc.) helps avoid race conditions.\n",
        "\n",
        "4. When the Global Interpreter Lock (GIL) is not a concern (in languages like Python):\n",
        "\n",
        "If the threading bottleneck is on waiting for non-CPU tasks (like database queries or HTTP requests), the GIL's limitation on threads can be mitigated since threads are mostly idle during this waiting time.\n",
        "\n",
        "***When Multiprocessing is Preferable:***\n",
        "\n",
        "Multiprocessing is more suitable for CPU-bound tasks where each process needs its own dedicated CPU time and where avoiding the limitations of Python’s Global Interpreter Lock (GIL) is important.\n",
        "\n",
        "1. CPU-bound tasks:\n",
        "\n",
        "Heavy computational tasks: When performing CPU-intensive tasks like image processing, number crunching, scientific simulations, or complex data transformations, multiprocessing takes full advantage of multiple CPU cores. Each process can run on its own CPU core independently.\n",
        "\n",
        "Machine learning: Training machine learning models or running simulations often require intensive computation. Using multiple processes allows for distributed computation without being limited by the GIL.\n",
        "\n",
        "2. Bypassing Python’s Global Interpreter Lock (GIL):\n",
        "\n",
        "Python’s GIL limits CPU-bound multithreading because it only allows one thread to execute Python bytecode at a time. Multiprocessing spawns separate processes, each with its own Python interpreter and GIL, thus enabling true parallelism for CPU-bound tasks.\n",
        "\n",
        "3. Tasks with isolated memory requirements:\n",
        "\n",
        "Data isolation: In cases where each task should operate on its own isolated memory space (e.g., when there is no need to share data between tasks or sharing data might introduce complexity), multiprocessing is more suitable. Each process runs in its own memory space, reducing the risk of race conditions or data corruption.\n",
        "\n",
        "Memory-intensive tasks: When each task needs its own large block of memory (e.g., processing large files independently), multiprocessing is better because each process has its own memory space, whereas threads share memory and can introduce overhead in managing large data sets.\n",
        "\n",
        "4. Fault tolerance:\n",
        "\n",
        "Process failures: If one process in a multiprocessing system fails, it won't affect the others because they run in separate memory spaces. With multithreading, a thread crash can potentially affect the entire program.\n"
      ],
      "metadata": {
        "id": "EIwr832BfW_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
      ],
      "metadata": {
        "id": "mMTEUKdxgipA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A process pool is a high-level abstraction that manages a collection of worker processes, allowing a program to distribute tasks efficiently across multiple processes without manually spawning and managing them. This is particularly useful in scenarios that require parallelism, where multiple tasks need to be executed concurrently to improve performance.\n",
        "\n",
        "The key concept of a process pool is that it provides a pool of reusable processes that can be assigned tasks dynamically, rather than creating a new process for each task. This reduces the overhead associated with repeatedly creating and destroying processes.\n",
        "\n",
        "***How a Process Pool Works:***\n",
        "\n",
        "1. Pre-initialized Worker Processes:\n",
        "\n",
        "The pool starts by initializing a fixed number of worker processes (based on the number of CPU cores or other resource considerations).\n",
        "These processes remain alive and are reused to perform multiple tasks, saving the overhead of process creation/destruction for each task.\n",
        "\n",
        "2. Task Queuing:\n",
        "\n",
        "When tasks (functions or workloads) are submitted to the pool, they are placed in a queue.\n",
        "\n",
        "The pool distributes these tasks to the available worker processes in the pool.\n",
        "\n",
        "3. Task Execution and Result Handling:\n",
        "\n",
        "Each worker process picks up a task from the queue, executes it, and returns the result when completed.\n",
        "\n",
        "The pool can manage collecting the results from each process and providing them back to the main program.\n",
        "\n",
        "4. Reusing Processes:\n",
        "\n",
        "Once a worker finishes a task, it is immediately available to pick up another task from the queue, thus reducing the time spent creating new processes.\n",
        "\n",
        "5. Dynamic Scaling (in some implementations):\n",
        "\n",
        "Some process pool implementations allow for dynamic scaling, where the number of worker processes can grow or shrink depending on the workload.\n",
        "\n",
        "***Advantages of Using a Process Pool:***\n",
        "\n",
        "1. Efficient Resource Utilization:\n",
        "\n",
        "By reusing a fixed number of processes, the process pool avoids the overhead of constantly creating and destroying processes. This is particularly important because creating a process is relatively expensive (in terms of time and memory) compared to creating a thread.\n",
        "\n",
        "The process pool ensures that the available CPU cores are fully utilized without overloading the system with too many processes.\n",
        "\n",
        "2. Simplified Process Management:\n",
        "\n",
        "Managing processes manually (spawning, monitoring, and terminating them) can be complex. A process pool abstracts this complexity and provides a convenient interface for submitting tasks and retrieving results.\n",
        "\n",
        "It ensures that the right number of processes is used, based on system resources and workload requirements, without the developer needing to explicitly manage each one.\n",
        "\n",
        "3. Avoids Resource Contention:\n",
        "\n",
        "By limiting the number of processes to a reasonable number (typically tied to the number of CPU cores), a process pool helps avoid excessive resource contention and ensures that system resources (e.g., CPU, memory) are used optimally.\n",
        "\n",
        "4. Load Balancing:\n",
        "\n",
        "The process pool distributes tasks across the available processes, helping balance the workload. This prevents some processes from being idle while others are overworked, leading to better overall performance.\n",
        "\n",
        "5. Parallelism with Simpler API:\n",
        "\n",
        "Many programming languages and libraries (such as Python’s multiprocessing.Pool) provide simple APIs for working with process pools, allowing developers to easily parallelize tasks without worrying about low-level process management.\n",
        "\n",
        "***Key Methods of a Process Pool:***\n",
        "\n",
        "1. pool.map(func, iterable):\n",
        "\n",
        "Distributes the tasks (from the iterable) across the worker processes, applies the function func to each element, and collects the results.\n",
        "\n",
        "2. pool.apply(func, args):\n",
        "\n",
        "Executes a single task with the given arguments on one of the workers and returns the result.\n",
        "\n",
        "3. pool.apply_async(func, args):\n",
        "\n",
        "Similar to apply(), but allows for asynchronous execution. The task is sent to a worker process, and the result can be retrieved later.\n",
        "\n",
        "4. pool.starmap(func, iterable):\n",
        "\n",
        "Similar to map(), but it allows functions with multiple arguments. Each element in the iterable must be an argument tuple.\n",
        "\n",
        "5. pool.close() and pool.join():\n",
        "\n",
        "close(): Prevents any more tasks from being submitted to the pool.\n",
        "\n",
        "join(): Waits for all worker processes to finish their tasks before proceeding."
      ],
      "metadata": {
        "id": "RZtyS7CUg1Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example using multiprocessing.Pool:\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Function to be executed by multiple processes\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a process pool with 4 worker processes\n",
        "    with Pool(processes=4) as pool:\n",
        "        # Map a list of inputs to the function using the pool\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "\n",
        "    # Print the results\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh9oMLT7hp1d",
        "outputId": "2855c156-d1a6-44d2-bd8c-b2cf32c2e28e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Explain what multiprocessing is and why it is used in Python programs."
      ],
      "metadata": {
        "id": "hOM-nN8kiXwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiprocessing is a parallel computing technique where multiple processes are executed simultaneously, each running on separate CPU cores or threads. Each process has its own memory space and resources, making it independent of other processes. This allows for true parallelism, where multiple tasks can be processed concurrently, improving performance for tasks that require heavy computation.\n",
        "\n",
        "In contrast to multithreading, where threads share the same memory space and may experience contention due to shared data, multiprocessing offers complete isolation between processes, which makes it ideal for CPU-bound tasks that need independent execution.\n",
        "\n",
        "***Why Use Multiprocessing in Python Programs?***\n",
        "\n",
        "1. Overcoming the GIL for CPU-bound Tasks:\n",
        "\n",
        "The most common reason for using multiprocessing in Python is to overcome the limitations of the GIL. For tasks that involve heavy CPU computation, using multiple threads would not result in significant speedups, but using multiple processes allows Python programs to take full advantage of multicore CPUs.\n",
        "\n",
        "2. CPU-bound Tasks:\n",
        "\n",
        "Multiprocessing is ideal for CPU-bound tasks, which are tasks that require significant computation and processing power. Examples include:\n",
        "\n",
        "(i) Image or video processing.\n",
        "\n",
        "(ii) Machine learning model training.\n",
        "\n",
        "(iii) Data transformation and analysis.\n",
        "\n",
        "(iv) Scientific simulations.\n",
        "\n",
        "3. Parallel Execution on Multiple Cores:\n",
        "\n",
        "On a multicore machine, using multiple processes enables the program to run on multiple cores simultaneously, which can significantly speed up execution time for computationally intensive tasks.\n",
        "\n",
        "4. Scalability:\n",
        "\n",
        "Multiprocessing can scale across multiple cores or even multiple machines (using frameworks like mpi4py or cloud-based distributed systems), making it suitable for large-scale computing tasks that need distributed parallelism."
      ],
      "metadata": {
        "id": "tyxzOEzniiZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock."
      ],
      "metadata": {
        "id": "8lHLiHq_jMWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared resource\n",
        "shared_list = []\n",
        "\n",
        "# Create a lock object\n",
        "lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(1, 11):  # Add numbers from 1 to 10\n",
        "        time.sleep(1)  # Simulate some delay\n",
        "        lock.acquire()  # Acquire the lock before modifying the list\n",
        "        try:\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added {i} to the list. Current list: {shared_list}\")\n",
        "        finally:\n",
        "            lock.release()  # Release the lock after modifying the list\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    for i in range(1, 11):  # Remove 10 numbers\n",
        "        time.sleep(2)  # Simulate some delay (removal slower than addition)\n",
        "        lock.acquire()  # Acquire the lock before modifying the list\n",
        "        try:\n",
        "            if shared_list:\n",
        "                removed = shared_list.pop(0)\n",
        "                print(f\"Removed {removed} from the list. Current list: {shared_list}\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove.\")\n",
        "        finally:\n",
        "            lock.release()  # Release the lock after modifying the list\n",
        "\n",
        "# Create threads for adding and removing numbers\n",
        "adder_thread = threading.Thread(target=add_numbers)\n",
        "remover_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "# Start the threads\n",
        "adder_thread.start()\n",
        "remover_thread.start()\n",
        "\n",
        "# Wait for both threads to finish\n",
        "adder_thread.join()\n",
        "remover_thread.join()\n",
        "\n",
        "print(\"Final list:\", shared_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCyXg70uj6Ok",
        "outputId": "60e36671-c04c-44c0-b28d-09f6e098da4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 1 to the list. Current list: [1]\n",
            "Removed 1 from the list. Current list: []\n",
            "Added 2 to the list. Current list: [2]\n",
            "Added 3 to the list. Current list: [2, 3]\n",
            "Removed 2 from the list. Current list: [3]\n",
            "Added 4 to the list. Current list: [3, 4]\n",
            "Added 5 to the list. Current list: [3, 4, 5]\n",
            "Removed 3 from the list. Current list: [4, 5]\n",
            "Added 6 to the list. Current list: [4, 5, 6]\n",
            "Added 7 to the list. Current list: [4, 5, 6, 7]\n",
            "Removed 4 from the list. Current list: [5, 6, 7]\n",
            "Added 8 to the list. Current list: [5, 6, 7, 8]\n",
            "Added 9 to the list. Current list: [5, 6, 7, 8, 9]\n",
            "Removed 5 from the list. Current list: [6, 7, 8, 9]\n",
            "Added 10 to the list. Current list: [6, 7, 8, 9, 10]\n",
            "Removed 6 from the list. Current list: [7, 8, 9, 10]\n",
            "Removed 7 from the list. Current list: [8, 9, 10]\n",
            "Removed 8 from the list. Current list: [9, 10]\n",
            "Removed 9 from the list. Current list: [10]\n",
            "Removed 10 from the list. Current list: []\n",
            "Final list: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Describe the methods and tools available in Python for safely sharing data between threads and processes."
      ],
      "metadata": {
        "id": "EZ03sWAEkDg_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python offers several mechanisms to safely share data between threads and processes, ensuring data integrity and avoiding race conditions.\n",
        "\n",
        "***Sharing Data Between Threads***\n",
        "\n",
        "1. Thread-local Storage (TLS):\n",
        "\n",
        "Each thread has its own copy of a variable.\n",
        "Useful for data that is specific to a thread, such as user preferences or connection information.\n",
        "\n",
        "2. Shared Variables with Locks:\n",
        "\n",
        "Use a shared variable (e.g., a list or dictionary) along with a lock to protect access.\n",
        "\n",
        "Acquire the lock before accessing the shared variable and release it afterward.\n",
        "\n",
        "3. Queues:\n",
        "\n",
        "Use queue.Queue to provide thread-safe communication and synchronization.\n",
        "Producers add items to the queue, and consumers remove them.\n",
        "\n",
        "***Sharing Data Between Processes***\n",
        "\n",
        "1. Shared Memory:\n",
        "\n",
        "Use libraries like mmap or multiprocessing.shared_memory to create shared memory segments.\n",
        "\n",
        "Processes can access and modify the shared memory directly.\n",
        "\n",
        "2. Pipes:\n",
        "\n",
        "Use os.pipe or multiprocessing.Pipe to create unidirectional or bidirectional pipes.\n",
        "\n",
        "Processes can communicate by sending and receiving data through the pipes.\n",
        "\n",
        "3. Queues:\n",
        "\n",
        "Use multiprocessing.Queue for inter-process communication.\n",
        "\n",
        "Similar to thread queues, but for processes."
      ],
      "metadata": {
        "id": "WElNfqCOkkgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so."
      ],
      "metadata": {
        "id": "SuaHxLS2lRfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Exception handling in concurrent programs is critical for several reasons:***\n",
        "\n",
        "Preventing Deadlocks: Unhandled exceptions in one thread can lead to the entire program freezing if not properly managed.\n",
        "\n",
        "Ensuring Correctness: Exceptions can indicate unexpected conditions that require specific handling to maintain the program's correctness.\n",
        "\n",
        "Improving Reliability: By anticipating and handling potential exceptions, concurrent programs become more robust and less prone to failures.\n",
        "\n",
        "***Here are some effective techniques for handling exceptions in concurrent programs:***\n",
        "\n",
        "1. Thread-Specific Exception Handlers:Each thread can have its own exception handler, allowing for tailored responses to different error conditions.\n",
        "This can help isolate the impact of exceptions and prevent them from affecting other threads.\n",
        "2. Global Exception Handlers:\n",
        "A global exception handler can catch exceptions that propagate to the top level of the program.\n",
        "This can be useful for logging errors, providing informative messages, or performing cleanup tasks.\n",
        "3. Exception Queues:\n",
        "Exceptions can be placed in a queue for later processing by a dedicated thread or process.\n",
        "This can help prevent the main thread from being blocked by exceptions and improve overall responsiveness.\n",
        "4. Exception Propagation:\n",
        "Exceptions can be propagated up the call stack until they are caught by a suitable handler.\n",
        "This allows for hierarchical exception handling and can help identify the root cause of errors.\n",
        "5. Exception Isolation:\n",
        "Using techniques like thread isolation or process isolation can help contain the impact of exceptions to a specific part of the program.\n",
        "This can prevent exceptions from cascading and causing unintended side effects.\n",
        "6. Context Managers and try-finally Blocks:\n",
        "These constructs can be used to ensure that resources are properly released, even if exceptions occur.\n",
        "This is particularly important in concurrent programs where resources like locks or database connections need to be managed carefully.\n",
        "7. Logging and Debugging:\n",
        "Logging exceptions can provide valuable information for debugging and troubleshooting.\n",
        "Using a debugger can also help identify the root cause of exceptions and trace their propagation through the code."
      ],
      "metadata": {
        "id": "3-J6GZ7MlcwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads."
      ],
      "metadata": {
        "id": "6vKvKwHm4ZKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate the factorial of a number\n",
        "def factorial(n):\n",
        "    print(f\"Calculating factorial of {n}\")\n",
        "    return math.factorial(n)\n",
        "\n",
        "# List of numbers for which we will calculate factorials\n",
        "numbers = list(range(1, 11))\n",
        "\n",
        "# Use ThreadPoolExecutor to manage the threads\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    # Submit tasks to the thread pool and get the results\n",
        "    results = list(executor.map(factorial, numbers))\n",
        "\n",
        "# Print the results\n",
        "for num, result in zip(numbers, results):\n",
        "    print(f\"Factorial of {num} is {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_aNszDT4vOU",
        "outputId": "98e40421-e5c3-445f-9242-a7984d9dca52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating factorial of 1Calculating factorial of 2\n",
            "\n",
            "Calculating factorial of 3\n",
            "Calculating factorial of 4\n",
            "Calculating factorial of 5Calculating factorial of 6\n",
            "\n",
            "Calculating factorial of 7\n",
            "Calculating factorial of 8\n",
            "Calculating factorial of 9Calculating factorial of 10\n",
            "\n",
            "Factorial of 1 is 1\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 4 is 24\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes)."
      ],
      "metadata": {
        "id": "QHd6wa67450i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "def main():\n",
        "    num_processes_list = [2, 4, 8]\n",
        "\n",
        "    for num_processes in num_processes_list:\n",
        "        start_time = time.time()\n",
        "\n",
        "        with multiprocessing.Pool(processes=num_processes) as pool:\n",
        "            results = pool.map(square, range(1, 11))\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        print(f\"Using {num_processes} processes:\")\n",
        "        print(f\"Results: {results}\")\n",
        "        print(f\"Time taken: {end_time - start_time} seconds\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bko1MIbm49tN",
        "outputId": "3441d454-d2d6-47de-abcb-ecdcd3bbbf88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 2 processes:\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.033217430114746094 seconds\n",
            "\n",
            "Using 4 processes:\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.05211949348449707 seconds\n",
            "\n",
            "Using 8 processes:\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.09233236312866211 seconds\n",
            "\n"
          ]
        }
      ]
    }
  ]
}